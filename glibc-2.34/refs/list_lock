<def f='codebrowser/malloc/arena.c' l='99' macro='1' type='__libc_lock_t'/>
<use f='codebrowser/malloc/arena.c' l='154' u='a' c='__malloc_fork_lock_parent'/>
<use f='codebrowser/malloc/arena.c' l='178' u='a' c='__malloc_fork_unlock_parent'/>
<use f='codebrowser/malloc/arena.c' l='208' u='w' c='__malloc_fork_unlock_child'/>
<doc f='codebrowser/malloc/arena.c' l='87'>/* list_lock prevents concurrent writes to the next member of struct
   malloc_state objects.

   Read access to the next member is supposed to synchronize with the
   atomic_write_barrier and the write to the next member in
   _int_new_arena.  This suffers from data races; see the FIXME
   comments in _int_new_arena and reused_arena.

   list_lock also prevents concurrent forks.  At the time list_lock is
   acquired, no arena lock must have been acquired, but it is
   permitted to acquire arena locks subsequently, while list_lock is
   acquired.  */</doc>
