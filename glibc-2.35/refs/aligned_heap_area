<def f='codebrowser/malloc/arena.c' l='476' type='char *'/>
<use f='codebrowser/malloc/arena.c' l='506' u='r' c='alloc_new_heap'/>
<use f='codebrowser/malloc/arena.c' l='508' u='r' c='alloc_new_heap'/>
<use f='codebrowser/malloc/arena.c' l='509' u='w' c='alloc_new_heap'/>
<use f='codebrowser/malloc/arena.c' l='527' u='w' c='alloc_new_heap'/>
<use f='codebrowser/malloc/arena.c' l='671' u='r' c='heap_trim'/>
<use f='codebrowser/malloc/arena.c' l='672' u='w' c='heap_trim'/>
<doc f='codebrowser/malloc/arena.c' l='468'>/* If consecutive mmap (0, HEAP_MAX_SIZE &lt;&lt; 1, ...) calls return decreasing
   addresses as opposed to increasing, new_heap would badly fragment the
   address space.  In that case remember the second HEAP_MAX_SIZE part
   aligned to HEAP_MAX_SIZE from last mmap (0, HEAP_MAX_SIZE &lt;&lt; 1, ...)
   call (if it is already aligned) and try to reuse it next time.  We need
   no locking for it, as kernel ensures the atomicity for us - worst case
   we&apos;ll call mmap (addr, HEAP_MAX_SIZE, ...) for some value of addr in
   multiple threads, but only one will succeed.  */</doc>
